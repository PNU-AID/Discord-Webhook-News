import os  # osëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸° (ìš´ì˜ì²´ì œì™€ì˜ ìƒí˜¸ì‘ìš©ì„ ë•ëŠ” ë‹¤ì–‘í•œ ê¸°ëŠ¥ ì œê³µ )

import requests  # requestsëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°(http, https ì›¹ ì‚¬ì´íŠ¸ì— ìš”ì²­í•˜ê¸° ìœ„í•´ ìì£¼ ì‚¬ìš©ë˜ëŠ” ëª¨ë“ˆ)
from bs4 import (
    BeautifulSoup,  # ì›¹ ë°ì´í„° í¬ë¡¤ë§ ë„ëŠ” ìŠ¤í¬ë˜í•‘ì„ í•  ë•Œ ì‚¬ìš©í•˜ëŠ” python ë¼ì´ë¸ŒëŸ¬ë¦¬
)
from dotenv import load_dotenv  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬

load_dotenv(dotenv_path=".env")  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì— ìˆëŠ” .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œ
DISCORD_URL = os.getenv("DISCORD_URL")  # os.getenv()ëŠ” í•¨ìˆ˜ëŠ” ì§€ì •ëœ í™˜ê²½ ë³€ìˆ˜ì˜ ê°’ì„ ë°˜í™˜í•˜ê±°ë‚˜, í•´ë‹¹ í™˜ê²½ ë³€ìˆ˜ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ Noneì„ ë°˜í™˜
GEEKNEWS_BASEURL = "https://news.hada.io/"  #
GEEKNEWS_URL = "https://news.hada.io/new"
want_to_include = ["AI", "ai", "ML", "GPT", "LLM", "Diffusion", "ì¸ê³µì§€ëŠ¥", "ë”¥ëŸ¬ë‹", "ë¨¸ì‹ ëŸ¬ë‹", "ì‚¬ì „í•™ìŠµ", "íŒŒì¸íŠœë‹"]
days_included = [f"{i}ë¶„ì „" for i in range(1, 20)]


headers = {"Content-Type": "application/json"}
messages = []

response = requests.get(GEEKNEWS_URL)
if response.status_code == 200:
    html = response.text
    soup = BeautifulSoup(html, "html.parser")
    topics = soup.find_all("div", class_="topic_row")
    for topic in topics:
        topic_title = topic.find("div", class_="topictitle")
        topic_content = topic.find("div", class_="topicdesc")
        topic_url = topic.find("span", class_="topicurl")
        topic_info = topic.find("div", class_="topicinfo")
        topic_date = topic_info.text.split(" ")[4]

        if topic_title.a is None:
            title = topic_title.h1.string
        else:
            title = topic_title.a.h1.string
            # topic_link = topic_title.find("a")["href"].strip()

        description = ""
        if topic_content is not None:
            description = topic_content.a.string
            topic_link = topic_content.find("a")["href"].strip()
        else:
            topic_link = topic_title.find("a")["href"].strip()
        flag = False

        if topic_url.string is None:
            continue

        for days in days_included:
            if days == topic_date:
                flag = True
                break

        if not flag:
            continue

        for word in want_to_include:
            if word in title or word in description:
                message = f"## ğŸ“{title}\n\n ë§í¬ : {GEEKNEWS_BASEURL + topic_link}"
                messages.append(message)
                break

else:
    print(f"Error: {response.status_code}")


if len(messages) != 0:
    for message in messages:
        data = {"content": message}
        response = requests.post(DISCORD_URL, json=data)
        if response.status_code == 404:
            print("response code is 404, check discord url or action variable")
